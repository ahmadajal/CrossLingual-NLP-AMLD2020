{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sklearn_LASER_cross_language_embd.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ioannispartalas/CrossLingual-NLP-AMLD2020/blob/master/sklearn_LASER_cross_language_embd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9x6-u2lxYkP",
        "colab_type": "text"
      },
      "source": [
        "# Cross lingual processing and Transfer Learning using multi-linguale embedding\n",
        "\n",
        "Facebook AI has released a multilingual toolkit called LASER (Language-Agnostic SEntence Representations) relying on sequence to sequence autoencoder. Sequence encoder has the undisputable advantage to process directly language sentences and thus apture their internal structures.\n",
        "\n",
        "LASER has been trained over more than 100 languages which permits to project through the encoder any sentences from those languages in a common representation, called multi-lingual embedding  space.\n",
        "<figure>\n",
        "<img src= \"https://engineering.fb.com/wp-content/uploads/2019/01/CodeBlog_embedding_space_v4.png\" style= \"width=45%\">\n",
        " <figcaption>Fig.1 - Multinlingual embedding.</figcaption>\n",
        "</figure>\n",
        "\n",
        "On this notebook, we will work on a multilingual dataset containing sentences in four languages: english, dutch, spanish and russian. Every sentence of every language comes along a with sentiment label indicating positive or negative content. There is no sentence overlapp between idioms. We directly provide the sentence embedding for all langauges. Every sentence is represented by a 1024 dimensional vector indicating its position in LASER."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qnXLnDSxFCL",
        "colab_type": "code",
        "outputId": "8cc313d6-a094-4a0a-ca8f-7745606d93c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "#Let's download the dataset\n",
        "!git clone https://github.com/ioannispartalas/CrossLingual-NLP-AMLD2020.git\n",
        "#Data are in copied in ./CrossLingual-NLP-AMLD2020/data/laser/ of your colab local filesystem\n",
        "!ls ./CrossLingual-NLP-AMLD2020/data/laser/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CrossLingual-NLP-AMLD2020'...\n",
            "remote: Enumerating objects: 132, done.\u001b[K\n",
            "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
            "remote: Compressing objects: 100% (102/102), done.\u001b[K\n",
            "remote: Total 132 (delta 57), reused 66 (delta 22), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (132/132), 36.67 MiB | 16.16 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "en_laser_test.npy\t  es_test_labels_adan.txt   ru_laser_test.npy\n",
            "en_laser_train.npy\t  es_train_labels_adan.txt  ru_laser_train.npy\n",
            "en_test_labels_adan.txt   nl_laser_test.npy\t    ru_test_labels_adan.txt\n",
            "en_train_labels_adan.txt  nl_laser_train.npy\t    ru_train_labels_adan.txt\n",
            "es_laser_test.npy\t  nl_test_labels_adan.txt\n",
            "es_laser_train.npy\t  nl_train_labels_adan.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5uVWdjc4US0",
        "colab_type": "text"
      },
      "source": [
        "The dataset is made of numpy files:\n",
        "```\n",
        "'en_laser_train.npy'\n",
        "'en_laser_test.npy'\n",
        "'nl_laser_test.npy'\n",
        "...\n",
        "```\n",
        "containing respectively training and test set for every language. \n",
        "\n",
        "Corresponding labels are stored in \n",
        "```\n",
        "en_train_labels_adan.txt\n",
        "en_test_labels_adan.txt\n",
        "nl_laser_train.npy\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLIhEatowOB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import random as rn\n",
        "\n",
        "sys.path.insert(1, './CrossLingual-NLP-AMLD2020/')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oApGXIl8jU2Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# set seeds for reproducibility\n",
        "np.random.seed(12)\n",
        "rn.seed(1236)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uszr22lxk0hC",
        "colab_type": "text"
      },
      "source": [
        "First let's define io function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZAqYWf6_8nY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_language(language = 'en', train_or_test = 'train'):\n",
        "    \"\"\"\n",
        "    load dataset for a particular language and dataset (train or test)\n",
        "    \"\"\"\n",
        "    path = './CrossLingual-NLP-AMLD2020/data/laser/'\n",
        "    feat_fn =  path  + language + '_laser_' + train_or_test + '.npy'\n",
        "    label_fn = path  + language + '_' + train_or_test + '_labels_adan.txt'\n",
        "    labels = np.loadtxt(label_fn) \n",
        "    kk = np.squeeze(np.where(labels != 2))\n",
        "    feat = np.load(feat_fn)[kk]\n",
        "    labels = labels[kk]\n",
        "    return feat,labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldZjtvZdmEMz",
        "colab_type": "text"
      },
      "source": [
        "For model performance evaluation, the [F1](https://en.wikipedia.org/wiki/F1_score) score will be used as it is better suited than the traditional accuracy for imbalanced dataset. [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) is also an important metric to analyse model outputs in details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AloTmSlbk-Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "def cross_lang_evaluation(model):\n",
        "  \"\"\"\n",
        "  Measure F1 score and confusion matrix for the provided model over test data for the 4 languages\n",
        "  \"\"\"\n",
        "  languages = ['en','nl','es','ru']\n",
        "  EVAL = {}\n",
        "  for lang in languages:\n",
        "    x_test,y_test = load_language(lang, 'test')\n",
        "    y_pred = model.predict(x_test)\n",
        "    F1 = f1_score (y_test,y_pred)\n",
        "    CONF =  confusion_matrix(y_test,y_pred)\n",
        "    EVAL[lang] = (F1,CONF)\n",
        "  for lang, metric in EVAL.items():\n",
        "    print(lang,': ', metric[0],'\\n', metric[1],'\\n')\n",
        "  return EVAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjsJKOSmpEo0",
        "colab_type": "text"
      },
      "source": [
        "Let's train a logistic regression on one language, english for instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB4oz2LD72lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "x_train,y_train = load_language('en', 'train')  \n",
        "lr = LogisticRegression().fit(x_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wim0DcAopcNL",
        "colab_type": "text"
      },
      "source": [
        "And reuse this english model to predict sentiment on all languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU1No16mLALv",
        "colab_type": "code",
        "outputId": "0ebdcca8-2b6b-42a2-d098-5b4902628598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "_ = cross_lang_evaluation(lr)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en :  0.8875878220140515 \n",
            " [[379  42]\n",
            " [ 54  81]] \n",
            "\n",
            "nl :  0.839041095890411 \n",
            " [[245  15]\n",
            " [ 79  90]] \n",
            "\n",
            "es :  0.8922155688622755 \n",
            " [[447  13]\n",
            " [ 95  90]] \n",
            "\n",
            "ru :  0.89358372456964 \n",
            " [[571  34]\n",
            " [102 127]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcFDEuQtpoFL",
        "colab_type": "text"
      },
      "source": [
        "Although the model is the more accurate for english (where the model has been trained), it is able to predict sentiment with a fairly good accuracy on other languages.  \n",
        "\n",
        "Let's try now different combination: train on all languages but english, predict english"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgzmBJYaDyRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_test,y_test = [],[],[],[]\n",
        "\n",
        "languages = ['nl','es','ru']\n",
        "for lang in languages:\n",
        "  x_tr,y_tr = load_language(lang,'train')  \n",
        "  x_train.append(x_tr)\n",
        "  y_train.append(y_tr)\n",
        "\n",
        "x_train =np.vstack(x_train)\n",
        "y_train =np.hstack(y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJEkbMwMEjgq",
        "colab_type": "code",
        "outputId": "bbbca6d8-703f-4627-adc3-38d8ec9facc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "lr_2 = LogisticRegression().fit(x_train,y_train)\n",
        "_ = cross_lang_evaluation(lr_2)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en :  0.8875878220140515 \n",
            " [[379  42]\n",
            " [ 54  81]] \n",
            "\n",
            "nl :  0.839041095890411 \n",
            " [[245  15]\n",
            " [ 79  90]] \n",
            "\n",
            "es :  0.8922155688622755 \n",
            " [[447  13]\n",
            " [ 95  90]] \n",
            "\n",
            "ru :  0.89358372456964 \n",
            " [[571  34]\n",
            " [102 127]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvAUeCZosnce",
        "colab_type": "text"
      },
      "source": [
        "Surprisingly, the new model is able to predict sentiment polarity in english with same accuracy as before without ever seeing any english sentences! \n",
        "\n",
        "Could we do better? Let's try more complex models, such as [multi layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCA27E34vlHO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "66a40ecf-268b-4df4-b69d-6cfa16998d1c"
      },
      "source": [
        " from sklearn.neural_network import MLPClassifier\n",
        " mlp = MLPClassifier(solver='lbfgs', \n",
        "                     hidden_layer_sizes=(128,128),\n",
        "                     activation = 'relu',\n",
        "                     alpha=1e-3,\n",
        "                     max_iter = 50,\n",
        "                     early_stopping =True,\n",
        "                     validation_fraction = 0.1, \n",
        "                     random_state=1)\\\n",
        "      \n",
        " _ = cross_lang_evaluation(mlp.fit(x_train,y_train))"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en :  0.8801020408163265 \n",
            " [[345  76]\n",
            " [ 18 117]] \n",
            "\n",
            "nl :  0.8927875243664717 \n",
            " [[229  31]\n",
            " [ 24 145]] \n",
            "\n",
            "es :  0.9293361884368309 \n",
            " [[434  26]\n",
            " [ 40 145]] \n",
            "\n",
            "ru :  0.9191836734693877 \n",
            " [[563  42]\n",
            " [ 57 172]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWVM12v_RXG3",
        "colab_type": "text"
      },
      "source": [
        "or [extreme gradient boosting](https://en.wikipedia.org/wiki/XGBoost) (xgboost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUaqSmH4Pvni",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b0b0093a-a82d-4bcf-9e89-d62fdeb78e83"
      },
      "source": [
        "import xgboost as xgb\n",
        "boost = xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
        "_ = cross_lang_evaluation(boost.fit(x_train,y_train))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en :  0.8709677419354838 \n",
            " [[351  70]\n",
            " [ 34 101]] \n",
            "\n",
            "nl :  0.8871595330739299 \n",
            " [[228  32]\n",
            " [ 26 143]] \n",
            "\n",
            "es :  0.9224318658280922 \n",
            " [[440  20]\n",
            " [ 54 131]] \n",
            "\n",
            "ru :  0.9129373474369405 \n",
            " [[561  44]\n",
            " [ 63 166]] \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvX_liTERnBB",
        "colab_type": "text"
      },
      "source": [
        "What can we conclude from the above results?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjWSdmjTRsOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}