{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de sklearn_LASER_cross_language_embd.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9x6-u2lxYkP",
        "colab_type": "text"
      },
      "source": [
        "# Cross lingual processing and Transfer Learning using multi-linguale embedding\n",
        "\n",
        "On this notebook, we will work on a multilingual dataset containing sentences in four languages: english, dutch, spanish and russian. Every sentence of every language comes along a with sentiment label indicating positive or negative content. There is no sentence overlapp between idioms. \n",
        "\n",
        "Working with the LASER multilinguale representation, we directly provide the sentence embedding for all languages. Every sentence is represented by a 1024 dimensional vector indicating its position in LASER."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGG1H0Vk2gWl",
        "colab_type": "text"
      },
      "source": [
        "# Loading data from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qnXLnDSxFCL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's download the dataset (if not done already)\n",
        "!git clone https://github.com/ioannispartalas/CrossLingual-NLP-AMLD2020.git\n",
        "#With this command, the path to the data is \n",
        "workdir = './CrossLingual-NLP-AMLD2020/'\n",
        "path_to_data =  workdir + 'data/laser/'  \n",
        "#Please check if this correct, otherwise correct path_to_data\n",
        "!ls ./CrossLingual-NLP-AMLD2020/data/laser/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5uVWdjc4US0",
        "colab_type": "text"
      },
      "source": [
        "The dataset is made of numpy files:\n",
        "```\n",
        "'en_laser_train.npy'\n",
        "'en_laser_test.npy'\n",
        "'nl_laser_test.npy'\n",
        "...\n",
        "```\n",
        "containing respectively training and test set for every language. \n",
        "\n",
        "Corresponding labels are stored in \n",
        "```\n",
        "en_train_labels_adan.txt\n",
        "en_test_labels_adan.txt\n",
        "nl_laser_train.npy\n",
        "...\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kLIhEatowOB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import random as rn\n",
        "import pandas as pd\n",
        "\n",
        "sys.path.insert(1, workdir)\n",
        "from src.utils import load_language\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldZjtvZdmEMz",
        "colab_type": "text"
      },
      "source": [
        "For model performance evaluation, the [F1](https://en.wikipedia.org/wiki/F1_score) score will be used as it is better suited than the traditional accuracy for imbalanced dataset. [Confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix) is also an important metric to analyse model outputs in details."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AloTmSlbk-Lo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "def cross_lang_evaluation(model):\n",
        "  \"\"\"\n",
        "  Measure F1 score and confusion matrix for the provided model over test data for the 4 languages\n",
        "  \"\"\"\n",
        "  languages = ['en','nl','es','ru']\n",
        "  EVAL = {}\n",
        "  for lang in languages:\n",
        "    x_test,y_test = load_language(path_to_data, lang, 'test')\n",
        "    y_pred = model.predict(x_test)\n",
        "\n",
        "    F1 = f1_score (y_test,y_pred, pos_label = 3)\n",
        "    CONF =  pd.DataFrame(confusion_matrix(y_test,y_pred),index = ['TRUE NEGATIVE','TRUE POSITIVE'],columns=('PRED NEGATIVE','PRED POSITIVE'))\n",
        "\n",
        "    EVAL[lang] = (F1,CONF)\n",
        "  for lang, metric in EVAL.items():\n",
        "    print(lang,': F1= ', metric[0],'\\n', metric[1],'\\n')\n",
        "  return EVAL"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjsJKOSmpEo0",
        "colab_type": "text"
      },
      "source": [
        "Let's train a logistic regression on one language, english for instance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB4oz2LD72lj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "x_train,y_train = load_language(path_to_data,'en', 'train')  \n",
        "lr = LogisticRegression(C = 10,random_state = 1).fit(x_train,y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wim0DcAopcNL",
        "colab_type": "text"
      },
      "source": [
        "And reuse this english model to predict sentiment on all languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU1No16mLALv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = cross_lang_evaluation(lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcFDEuQtpoFL",
        "colab_type": "text"
      },
      "source": [
        "Although the model is the more accurate for english (where the model has been trained), it is able to predict sentiment with a fairly good accuracy on other languages.  \n",
        "\n",
        "Let's try now different combination: train on all languages but english, predict english"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgzmBJYaDyRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train,y_train,x_test,y_test = [],[],[],[]\n",
        "\n",
        "languages = ['nl','es','ru']\n",
        "for lang in languages:\n",
        "  x_tr,y_tr = load_language(path_to_data,lang,'train')  \n",
        "  x_train.append(x_tr)\n",
        "  y_train.append(y_tr)\n",
        "\n",
        "x_train =np.vstack(x_train)\n",
        "y_train =np.hstack(y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJEkbMwMEjgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_2 = LogisticRegression(C = 10, max_iter = 200, random_state = 1).fit(x_train,y_train)\n",
        "_ = cross_lang_evaluation(lr_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvAUeCZosnce",
        "colab_type": "text"
      },
      "source": [
        "Surprisingly, the new model is able to predict sentiment polarity in english with same accuracy as before without ever seeing any english sentences! \n",
        "\n",
        "Could we do better? Let's try more complex models, such as [multi layer perceptron](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCA27E34vlHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.neural_network import MLPClassifier\n",
        " mlp = MLPClassifier(solver='lbfgs', \n",
        "                     hidden_layer_sizes=(128,128),\n",
        "                     activation = 'relu',\n",
        "                     alpha=1e-8,\n",
        "                     max_iter = 500,\n",
        "                     early_stopping =True,\n",
        "                     validation_fraction = 0.1, \n",
        "                     random_state=1)\\\n",
        "      \n",
        " _ = cross_lang_evaluation(mlp.fit(x_train,y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWVM12v_RXG3",
        "colab_type": "text"
      },
      "source": [
        "or [extreme gradient boosting](https://en.wikipedia.org/wiki/XGBoost) (xgboost)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUaqSmH4Pvni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "boost = xgb_model = xgb.XGBClassifier(objective=\"binary:logistic\",max_depth =3, random_state=42)\n",
        "_ = cross_lang_evaluation(boost.fit(x_train,y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvX_liTERnBB",
        "colab_type": "text"
      },
      "source": [
        "What can we conclude from the above results?"
      ]
    }
  ]
}