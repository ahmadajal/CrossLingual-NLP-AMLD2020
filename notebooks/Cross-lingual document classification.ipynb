{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem description\n",
    "\n",
    "Cross-lingual document classification (CLDC) is the text mining problem where we are given:\n",
    "- labeled documents for training in a source language $\\ell_1$, and \n",
    "- test documents written in a target language $\\ell_2$. \n",
    "\n",
    "For example, the training documents are written in English, and the test documents are written in French. \n",
    "\n",
    "\n",
    "CLDC is an interesting problem. The hope is that we can use resource-rich languages to train models that can be applied to resource-deprived languages. This would result in transferring knowledge from one language to another. \n",
    "There are several methods that can be used in this context. In this workshop we start from naive approaches and progressively introduce more complex solutions. \n",
    "\n",
    "The most naive solution is to ignore the fact the training and test documents are written in different languages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ipartalas/projects/LASER/\n",
      "/home/ipartalas/projects/LASER/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import Counter\n",
    "from models import *\n",
    "from utils import *\n",
    "from dataset import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Dataset: holds the data of sources and target language\n",
    "2. System: This is a set of steps: Does fit, predict. Can be in the form of a pipeline also\n",
    "3. Experiment: Given a Dataset and a System it fits, predicts and reports evaluation scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this workshop we will use a dataset from the [SemEval](http://alt.qcri.org/semeval2015/) workshop for the Sentiment Analysis task. While the tasks have three classes, that is **Positive, Negative, Neutral**, we will use only two classes in order to simplify it. So, let's load the data for a pair of languages and check a few statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data\n",
      "==========\n",
      "Training Data Shape:  (1635, 2)\n",
      "Class distribution:  {'positive': 1114, 'negative': 521}\n",
      "\n",
      "Training data\n",
      "==========\n",
      "Training Data Shape:  (644, 2)\n",
      "Class distribution:  {'positive': 455, 'negative': 189}\n",
      "Loaded 3315 vectors\n",
      "Loaded 1287 vectors\n"
     ]
    }
   ],
   "source": [
    "exp = Dataset(\"en\", \"es\")\n",
    "exp.load_data()\n",
    "exp.load_cl_embeddings(\"./\",300,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the datasets are unbalanced as we have much more positive comments that negative ones. We will start by establishing a few baselines and see how we can improve over them by leveraging cross-lingual word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ipartalas/virtual_envs/semeval-exps/lib/python3.7/site-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
      "  \"stratified to prior in 0.24.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3088235294117647"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Majority Class\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer()), \n",
    "                     ('classifier', DummyClassifier())])\n",
    "runner = Runner(pipeline, exp)\n",
    "runner.eval_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3515625"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression on words\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(lowercase=True)), \n",
    "                     ('classifier', LogisticRegression(solver=\"lbfgs\"))])\n",
    "runner = Runner(pipeline, exp)\n",
    "runner.eval_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5748031496062992"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_baseline = nBowClassifier(KNeighborsClassifier(n_neighbors=2),exp.source_embeddings,exp.target_embeddings)\n",
    "\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(lowercase=True,vocabulary=exp.vocab_)), \n",
    "                     ('classifier', avg_baseline)])\n",
    "\n",
    "runner = Runner(pipeline, exp)\n",
    "runner.eval_system()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knn 0.5748031496062992\n",
      "Log. Regression 0.6322188449848024\n"
     ]
    }
   ],
   "source": [
    "for name, myclf in zip(['Knn', 'Log. Regression'],[KNeighborsClassifier(n_neighbors=2), LogisticRegression(C=10, solver=\"lbfgs\")]):\n",
    "\n",
    "    avg_baseline = nBowClassifier(myclf,exp.source_embeddings,exp.target_embeddings)\n",
    "\n",
    "    pipeline = Pipeline([('vectorizer', CountVectorizer(lowercase=True,vocabulary=exp.vocab_)), \n",
    "                         ('classifier', avg_baseline)])\n",
    "\n",
    "    runner = Runner(pipeline, exp)\n",
    "    print(name, runner.eval_system())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Encoder: loading /home/ipartalas/projects/LASER/models/bilstm.93langs.2018-12-26.pt\n",
      " - Tokenizer: temp_in_docs.txt in language en  \n",
      " - fast BPE: processing tok\n",
      " - Encoder: bpe to out.raw\n",
      " - Encoder: 1635 sentences in 10s\n",
      " - Encoder: loading /home/ipartalas/projects/LASER/models/bilstm.93langs.2018-12-26.pt\n",
      " - Tokenizer: temp_in_docs.txt in language es  \n",
      " - fast BPE: processing tok\n",
      " - Encoder: bpe to out.raw\n",
      " - Encoder: 644 sentences in 7s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6493506493506493"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laser_clf = LASERClassifier(KNeighborsClassifier(n_neighbors=2), exp.source_lang, exp.target_lang)\n",
    "\n",
    "pipeline = Pipeline([(\"doc2laser\",Doc2Laser()),('classifier', laser_clf)])\n",
    "pipeline.set_params(doc2laser__lang=exp.source_lang)\n",
    "pipeline.fit(exp.train,exp.y_train)\n",
    "\n",
    "runner = Runner(pipeline, exp)\n",
    "\n",
    "pipeline.set_params(doc2laser__lang=exp.target_lang)\n",
    "runner.eval_system(prefit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - Encoder: loading /home/ipartalas/projects/LASER/models/bilstm.93langs.2018-12-26.pt\n",
      " - Tokenizer: temp_in_docs.txt in language en  \n",
      " - fast BPE: processing tok\n",
      " - Encoder: bpe to out.raw\n",
      " - Encoder: 1635 sentences in 7s\n",
      " - Encoder: loading /home/ipartalas/projects/LASER/models/bilstm.93langs.2018-12-26.pt\n",
      " - Tokenizer: temp_in_docs.txt in language es  \n",
      " - fast BPE: processing tok\n",
      " - Encoder: bpe to out.raw\n",
      " - Encoder: 644 sentences in 6s\n",
      "Knn 0.6493506493506493\n",
      " - Encoder: loading /home/ipartalas/projects/LASER/models/bilstm.93langs.2018-12-26.pt\n",
      " - Tokenizer: temp_in_docs.txt in language en  \n",
      " - fast BPE: processing tok\n",
      " - Encoder: bpe to out.raw\n",
      " - Encoder: 1635 sentences in 7s\n",
      " - Encoder: loading /home/ipartalas/projects/LASER/models/bilstm.93langs.2018-12-26.pt\n",
      " - Tokenizer: temp_in_docs.txt in language es  \n",
      " - fast BPE: processing tok\n",
      " - Encoder: bpe to out.raw\n",
      " - Encoder: 644 sentences in 6s\n",
      "Log. Regression 0.7714285714285715\n"
     ]
    }
   ],
   "source": [
    "for name, myclf in zip(['Knn', 'Log. Regression'],[KNeighborsClassifier(n_neighbors=2), LogisticRegression(C=10, solver=\"lbfgs\")]):\n",
    "    laser_clf = LASERClassifier(myclf, exp.source_lang, exp.target_lang)\n",
    "    pipeline = Pipeline([(\"doc2laser\",Doc2Laser()),('classifier', laser_clf)])\n",
    "    pipeline.set_params(doc2laser__lang=exp.source_lang)\n",
    "    pipeline.fit(exp.train,exp.y_train)\n",
    "    runner = Runner(pipeline, exp)\n",
    "\n",
    "    pipeline.set_params(doc2laser__lang=exp.target_lang)\n",
    "    print(name, runner.eval_system(prefit=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
